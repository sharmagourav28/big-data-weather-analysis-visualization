name: Upload ETL Script & Trigger Job & Crawler

on:
  push:
    branches:
      - blade

jobs:
  upload-run-etl-then-crawl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ secrets.REGION }}

      - name: Upload latest ETL script to S3
        run: |
          aws s3 cp my-etl-pipline/glue-script/weather-etl.py s3://fullautomatedbucket/scripts/weather-etl.py

      - name: Start Glue ETL Job
        id: start_etl
        run: |
          JOB_RUN_ID=$(aws glue start-job-run --job-name glue-etl-job --query 'JobRunId' --output text)
          echo "ETL JobRunId: $JOB_RUN_ID"
          echo "job_run_id=$JOB_RUN_ID" >> $GITHUB_OUTPUT

      - name: Wait for ETL Job to Complete
        run: |
          JOB_RUN_ID=${{ steps.start_etl.outputs.job_run_id }}
          while true; do
            STATUS=$(aws glue get-job-run --job-name glue-etl-job --run-id $JOB_RUN_ID --query 'JobRun.JobRunState' --output text)
            echo "ETL Job status: $STATUS"
            if [ "$STATUS" = "SUCCEEDED" ]; then
              echo "ETL Job completed successfully."
              break
            elif [ "$STATUS" = "FAILED" ] || [ "$STATUS" = "STOPPED" ]; then
              echo "ETL Job failed or was stopped."
              exit 1
            fi
            echo "Waiting for ETL job to complete..."
            sleep 30
          done

      - name: Start Glue Crawler
        run: |
          aws glue start-crawler --name my-etl-crawler
